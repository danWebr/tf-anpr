{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anpr_training_and_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZxewJesB7RC"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAo3cgeyr4WF"
      },
      "source": [
        "## (OPTIONAL) Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbdJj6FPSm5P"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQTCO5TmAIkv"
      },
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psnf8yxBr3hO"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY13s4XgsL-s"
      },
      "source": [
        "## Set paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBWPwvL7rKP"
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kRp8U4d7rM1"
      },
      "source": [
        "CUSTOM_MODEL_NAME = \"ssd_mobilenet\"\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4Lh4oKviXIR"
      },
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        " }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jEDJVTNiXOG"
      },
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecLLwOQCia_K"
      },
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        !mkdir -p {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd-cSmzjsiSO"
      },
      "source": [
        "## Clone Tensorflow Model Garden and install dependencies for object detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8liLErckTDV"
      },
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q3lsGN07rPb"
      },
      "source": [
        "%%bash\n",
        "sudo apt install -y protobuf-compiler\n",
        "cd Tensorflow/models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEmTV-0JDjRO"
      },
      "source": [
        "## Test installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEWXpjUV7rRu"
      },
      "source": [
        "%%bash\n",
        "cd Tensorflow/models/research/\n",
        "python3 object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB08Q5-oTv4n"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlEGTADcEPjl"
      },
      "source": [
        "## Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjqnMSIRswjM"
      },
      "source": [
        "This notebook expects a single archive with the following structure:\n",
        "```\n",
        "archive.tar.gz/\n",
        "  train/\n",
        "    picture1.png\n",
        "    picture1.xml\n",
        "    ...\n",
        "  test/\n",
        "    picture1.png\n",
        "    picture1.xml\n",
        "    ...\n",
        "```\n",
        "If your dataset doesn't match this structure you'll have to manually convert it accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IKuHU9rVopd"
      },
      "source": [
        "# Only needed when importing from Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clcAmeBpT1kl"
      },
      "source": [
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDl9mZum2lx9"
      },
      "source": [
        "## Download pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRm1Y6Xm2xDO"
      },
      "source": [
        "import object_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoudWDNOSaP2"
      },
      "source": [
        "!wget {PRETRAINED_MODEL_URL}\n",
        "!mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmOpnFxK21Xz"
      },
      "source": [
        "## Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_N9JPqSSaSa"
      },
      "source": [
        "labels = [{'name':'plate', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9mA5Ms73Chc"
      },
      "source": [
        "## Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdQd9kcgSaVH"
      },
      "source": [
        "%%bash\n",
        "cd Tensorflow/scripts\n",
        "wget https://raw.githubusercontent.com/nicknochnack/GenerateTFRecord/main/generate_tfrecord.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMBLK7saYFNK"
      },
      "source": [
        "Make sure that the following step correctly fills the .record files. If not you might have to run it twice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PsxK9F6SaXh"
      },
      "source": [
        "!python3 {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} -c {os.path.join(paths['ANNOTATION_PATH'], 'train.csv')}\n",
        "!python3 {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} -c {os.path.join(paths['ANNOTATION_PATH'], 'test.csv')}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2qtaL5oSaaI"
      },
      "source": [
        "!cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNf26EQgREAb"
      },
      "source": [
        "## Update config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzAl6KTzSacj"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IVCBa66SafE"
      },
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP4UL0umRQWc"
      },
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evQ91QjyRQla"
      },
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joHNOOpDRQn2"
      },
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
        "    f.write(config_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO0iB79dSAO_"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYKP2I6lws6c"
      },
      "source": [
        "cmd = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=500\".format(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py'), paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'])\n",
        "print(cmd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8_CMIbNAC5Y"
      },
      "source": [
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL5ocuRUShq9"
      },
      "source": [
        "# Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IlAPD5B7Rgd"
      },
      "source": [
        "cmd = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py'), paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
        "print(cmd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ7rTK36_-kp"
      },
      "source": [
        "!{cmd}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UreCENk7w04y"
      },
      "source": [
        "## (OPTIONAL) Visualize using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GKXqb4KSm-n"
      },
      "source": [
        "tb_path = os.path.join(paths['CHECKPOINT_PATH'], 'eval') # Change to 'train' if needed\n",
        "!cd {tb_path}\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6ID_8KFxhr5"
      },
      "source": [
        "# Install dependencies for OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Gd1mhErYT1"
      },
      "source": [
        "!pip3 install \"paddleocr>=2.0.1\" paddlepaddle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-0zr9YklxNV"
      },
      "source": [
        "# Run ANPR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDzsQbYxfh18"
      },
      "source": [
        "img = '\"/content/Tensorflow/workspace/images/test/images (13).jpg\"' # Path to image that you want to process"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nCqihJnl2zw"
      },
      "source": [
        "## Run using standard Python script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j4RfeJwrYY_"
      },
      "source": [
        "!python anpr_detector.py -i {img} -c {CUSTOM_MODEL_NAME} -cp 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34zGWFiFmHxB"
      },
      "source": [
        "## Run using IPython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdbOnMwrmK8z"
      },
      "source": [
        "Use this if you want to visualize the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA_cECHjVGOu"
      },
      "source": [
        "%run -i anpr_detector.py -i {img} -c {CUSTOM_MODEL_NAME} -cp 0"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}